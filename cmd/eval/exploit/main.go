package main

import (
	"fmt"
	"log/slog"
	"runtime"
	"sync"
	"time"

	"github.com/filevich/truco-mccfr-ai/bot"
	"github.com/filevich/truco-mccfr-ai/cfr"
	"github.com/filevich/truco-mccfr-ai/eval"
	"github.com/filevich/truco-mccfr-ai/eval/dataset"
	"github.com/filevich/truco-mccfr-ai/utils"
)

var (
	// base
	// b = "/media/jp/6e5bdfb0-c84b-4144-8d6d-4688934f1afe/models"
	// b = "/media/jp/6e5bdfb0-c84b-4144-8d6d-4688934f1afe/models/2p/FINAL-models-24h+48p-multi-core/a2"
	// b = "/media/jp/6e5bdfb0-c84b-4144-8d6d-4688934f1afe/models/4p/1Dpre-6Dnp+7Dp-multi12"

	// preliminary
	// r = "/truco-cfr/cmd/research"
	// p = "/cfr/checkpoints/preliminary"

	// models
	// m = "/models"

	// dataset
	// ds = eval.Load_dataset("/home/jp/Workspace/facu/pdg/truco-cfr/cmd/research/dataset-t1k22/out/T1K22.json")
	ds = dataset.LoadDataset("t1k22.json")
)

func main() {
	agents := []cfr.Agent{
		// &bot.Simple{},
		&bot.Random{},
	}

	numPlayers := 2
	tinyEval := 1_000

	for i, agent := range agents {
		ti := utils.MiniCurrentTime()
		fmt.Printf("[%s] (%d/%d) Explotando %s... \n", ti, i+1, len(agents), agent.UID())

		agent.Initialize()
		trainer := cfr.NewTrainer(
			cfr.BR_T,
			numPlayers,
			"sha160",
			"InfosetRondaBase",
			"a3",
		)

		evaluator := func() {
			agent := &cfr.BotCFR{
				ID:    trainer.String(),
				Model: trainer,
			}
			rr := eval.PlayMultipleDoubleGames(agent, agents, numPlayers, ds[:tinyEval])
			infos := trainer.CountInfosets()

			heapAlloc, totalAlloc, sys := utils.GetMemUsageMiB()

			var delta time.Duration = 0

			// general progress info
			slog.Info("REPORT", "infos", infos, "iters", trainer.Get_t())

			for i, r := range rr {
				delta += r.Delta
				u, l := r.WaldInterval(true)
				slog.Info(
					"RESULTS",
					"opponent", agents[i].UID(),
					"wr", r.WP(),
					"wald_interval_upper", u,
					"wald_interval_lower", l,
					"di", r.Dumbo1,
				)
			}
			slog.Info("EVAL_DONE", "delta", delta)
			slog.Info(
				"MEMORY",
				"heapAlloc", heapAlloc,
				"totalAlloc", totalAlloc,
				"sys", sys,
			)
		}

		trainer.Train(
			&cfr.ProfileTime{
				Exploiting:       agent,
				TotalRunningTime: 4*24*time.Hour + 23*time.Hour,
				PrunningTreshold: 3 * 24 * time.Hour,
				PrunningProb:     0.1,
				// multi
				Threads: 1,
				Mu:      &sync.Mutex{},
				// io
				SaveEvery:   cfr.NEVER,
				Silent:      true,
				FullySilent: true,
				SaveDir:     "/tmp/",
				SavePrefix:  "exploit_",
				// post save
				EvalEvery: time.Minute,
				Evaluator: evaluator,
				PostSave:  nil,
			},
		)

		// libero el modelo del agente
		agent.Free()
		runtime.GC()

		// print results?
	}

}
